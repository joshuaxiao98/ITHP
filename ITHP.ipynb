{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NQK-pUO3cWVr"},"outputs":[],"source":["import random\n","import sys\n","import scipy\n","import pickle \n","import argparse\n","import warnings\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","import torch.distributions as dist\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","source":["##Data Load"],"metadata":{"id":"AqipxndlV6el"}},{"cell_type":"code","source":["y = np.load('/content/drive/MyDrive/Colab Notebooks/Deep_Compact_Perception/MUStARD/sarcasm_labels.npy')\n","x_v = np.load('/content/drive/MyDrive/Colab Notebooks/Deep_Compact_Perception/MUStARD/video_features.npy')\n","print(x_v.shape)\n","x_a = np.load('/content/drive/MyDrive/Colab Notebooks/Deep_Compact_Perception/MUStARD/audio_fea.npy')[:,1:282]\n","print(x_a.shape)\n","x_t = np.load('/content/drive/MyDrive/Colab Notebooks/Deep_Compact_Perception/MUStARD/text_bert_embeddings.npy')\n","print(x_t.shape)"],"metadata":{"id":"bJiQz1Wn_1yD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684133905398,"user_tz":420,"elapsed":2,"user":{"displayName":"Xiongye Xiao","userId":"01666474114183755260"}},"outputId":"172ef900-82bc-4720-c63c-6d687014c4c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(690, 2048)\n","(690, 281)\n","(690, 768)\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","x_t_normalized = scaler.fit_transform(x_t)\n","x_a_normalized = scaler.fit_transform(x_a)\n","x_v_normalized = scaler.fit_transform(x_v)"],"metadata":{"id":"kJOBgUq5CVQ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## NN Model"],"metadata":{"id":"bOSKNZ1uvUYe"}},{"cell_type":"code","source":["############################### With Linear ##################################\n","class IBH(nn.Module):\n","    def __init__(self, input_dims, para_shift):\n","        super(IBH, self).__init__()\n","\n","        self.X0_dim = input_dims['X0_dim']\n","        self.X1_dim = input_dims['X1_dim']\n","        self.X2_dim = input_dims['X2_dim']\n","        self.inter_dim1 = input_dims['inter_dim1']\n","        self.inter_dim2 = input_dims['inter_dim2']\n","        self.drop_prob = input_dims['drop_prob']\n","        self.B0_dim = input_dims['B0_dim']\n","        self.B1_dim = input_dims['B1_dim']\n","        \n","        self.p_beta = para_shift['p_beta']\n","        self.p_gamma = para_shift['p_gamma']\n","        self.p_lambda = para_shift['p_lambda']\n","        \n","        self.encoder1 = nn.Sequential(\n","            nn.Linear(self.X0_dim, self.inter_dim1),\n","            nn.ReLU(),\n","            nn.Dropout(self.drop_prob),\n","            nn.Linear(self.inter_dim1, self.B0_dim * 2),\n","            # Dont add ReLU anymore!\n","        )\n","        \n","        self.decoder1 = nn.Sequential(\n","            nn.Linear(self.B0_dim, self.inter_dim1),\n","            nn.ReLU(),\n","            nn.Dropout(self.drop_prob),\n","            nn.Linear(self.inter_dim1, self.X1_dim),\n","            nn.Sigmoid(),\n","            nn.Dropout(self.drop_prob),\n","        )       \n","\n","        self.encoder2 = nn.Sequential(\n","            nn.Linear(self.B0_dim, self.inter_dim1),\n","            nn.ReLU(),\n","            nn.Dropout(self.drop_prob),\n","            nn.Linear(self.inter_dim1, self.B1_dim * 2),\n","            # Dont add ReLU anymore!\n","        )\n","\n","        self.decoder2 = nn.Sequential(\n","            nn.Linear(self.B1_dim, self.inter_dim1),\n","            nn.ReLU(),\n","            nn.Dropout(self.drop_prob),\n","            nn.Linear(self.inter_dim1, self.X2_dim),\n","            nn.Sigmoid(),\n","            nn.Dropout(self.drop_prob),\n","        )\n","\n","        self.fc1 = nn.Linear(self.B1_dim, self.inter_dim2)\n","        self.fc2 = nn.Linear(self.inter_dim2, 1)\n","\n","        self.criterion = nn.MSELoss()\n","\n","    def kl_loss(self, mu, logvar):\n","        kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp(), dim=-1)\n","        kl_mean = torch.mean(kl_div)\n","        return kl_mean\n","\n","    def reparameterise(self, mu, logvar):\n","        epsilon = torch.randn_like(mu)\n","        return mu + epsilon * torch.exp(logvar / 2)\n","\n","    def forward(self, x0, x1, x2):\n","        h1 = self.encoder1(x0)\n","        mu1, logvar1 = h1.chunk(2, dim=-1)\n","        kl_loss_0 = self.kl_loss(mu1, logvar1)\n","        b0 = self.reparameterise(mu1, logvar1)\n","        output1 = self.decoder1(b0)\n","\n","        mse_0 = self.criterion(output1, x1)\n","        IB0 = kl_loss_0 + self.p_beta * mse_0\n","        \n","        b0_sample = b0\n","        h2 = self.encoder2(b0_sample)\n","        mu2, logvar2 = h2.chunk(2, dim=-1)\n","\n","        kl_loss_1 = self.kl_loss(mu2, logvar2)\n","        b1 = self.reparameterise(mu2, logvar2)\n","        output2 = self.decoder2(b1)\n","        mse_1 = self.criterion(output2, x2)\n","        IB1 = kl_loss_1 + self.p_gamma * mse_1\n","        IB_total = IB0 + self.p_lambda * IB1\n","        \n","        b1 = b1.view(b1.size(0), -1)\n","        b1 = torch.relu(self.fc1(b1))\n","        y_pred = torch.sigmoid(self.fc2(b1))\n","\n","        return y_pred.squeeze(), IB_total"],"metadata":{"id":"FltMmtEWQsfz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############################### With Linear ##################################\n","class Unimodel(nn.Module):\n","    def __init__(self, input_dim):\n","        super(Unimodel, self).__init__()\n","\n","        self.fc1 = nn.Linear(input_dim, 64)\n","        self.fc2 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        \n","        x = x.view(x.size(0), -1)\n","        x = torch.relu(self.fc1(x))\n","        y_pred = torch.sigmoid(self.fc2(x))\n","\n","        return y_pred.squeeze()"],"metadata":{"id":"hlEqdJ_M_t3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","from sklearn.metrics import f1_score, recall_score\n","from sklearn.metrics import classification_report\n","n_splits = 5\n","kf = KFold(n_splits=n_splits, random_state=42,shuffle=True)"],"metadata":{"id":"ca0l8kn2nEfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre_list = [[] for i in range(n_splits)]\n","recall_list = [[] for i in range(n_splits)]\n","f1_list = [[] for i in range(n_splits)]\n","\n","input_dim = x_t.shape[-1]\n","\n","for fold, (train_index, test_index) in enumerate(kf.split(x_t)):\n","    model = Unimodel(input_dim)\n","    loss_func = nn.BCELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    print(f\"Fold {fold + 1}\")\n","\n","    x_train, x_test = x_t[train_index], x_t[test_index]\n","    y_train_np, y_test_np = y[train_index], y[test_index]\n","\n","    x_t_train = torch.tensor(x_train, dtype=torch.float32)\n","    x_t_test = torch.tensor(x_test, dtype=torch.float32)\n","\n","    y_train = torch.tensor(y_train_np,dtype=torch.float32)\n","    y_test = torch.tensor(y_test_np,dtype=torch.float32)\n","\n","    # Training\n","    for epoch in range(200):\n","        model.train()\n","        \n","        # Forward pass\n","        y_pred = model(x_t_train)\n","        \n","        # Compute loss\n","        loss = loss_func(y_pred, y_train)\n","        \n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Evaluate on the test set\n","        model.eval()\n","        with torch.no_grad():\n","            y_pred_test = model(x_t_test)\n","            y_pred_test = (y_pred_test > 0.5).float()\n","            result = classification_report(y_test.cpu().numpy(), y_pred_test.cpu().numpy(), output_dict=True, digits=3)\n","\n","            # Calculate F1-score and recall. Note that these functions expect numpy arrays.\n","            pre_list[fold].append(result[\"weighted avg\"][\"precision\"])\n","            recall_list[fold].append(result[\"weighted avg\"][\"recall\"])\n","            f1_list[fold].append(result[\"weighted avg\"][\"f1-score\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvBpKEoCAMob","executionInfo":{"status":"ok","timestamp":1684133951575,"user_tz":420,"elapsed":7997,"user":{"displayName":"Xiongye Xiao","userId":"01666474114183755260"}},"outputId":"7999e9bd-d234-4dcc-f3ba-aa136ebb1f89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n","Fold 2\n","Fold 3\n","Fold 4\n","Fold 5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HVh7DHHm2tR6"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}